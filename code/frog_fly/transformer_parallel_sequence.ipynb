{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 PPO + Transformer-Based Policy Network\n",
    "\n",
    "To incorporate temporal context into PPO, we replace the MLP policy with a Transformer policy.  \n",
    "Instead of conditioning only on the current state, the agent receives a short history of experience and attends to relevant past transitions.\n",
    "\n",
    "---\n",
    "\n",
    "### Sequential Input Representation\n",
    "\n",
    "At timestep \\(t\\), we construct a window of recent experience:\n",
    "\n",
    "$$\n",
    "\\mathcal{E}_t = \\big[(s_{t-T+1}, a_{t-T+1}), \\dots, (s_{t-1},a_{t-1}), (s_t,a_t)\\big]\n",
    "$$\n",
    "\n",
    "Each element is embedded using a small MLP:\n",
    "\n",
    "$$\n",
    "x_i = \\mathrm{MLP}_{\\text{embed}}([s_i, a_i])\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Temporal Positional Encoding\n",
    "\n",
    "Because self-attention is order-invariant, we inject temporal indices using sinusoidal encodings:\n",
    "\n",
    "$$\n",
    "PE(i) = [\\sin(\\omega_k i), \\cos(\\omega_k i)]_{k=1}^{F}\n",
    "$$\n",
    "\n",
    "The input token for the Transformer becomes:\n",
    "\n",
    "$$\n",
    "z_i = x_i \\;\\Vert\\; PE(i)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Transformer Encoder Block\n",
    "\n",
    "A Transformer layer processes the sequence by attending over past and recent experience:\n",
    "\n",
    "$$\n",
    "H^{(l+1)} = \\mathrm{LN}\\Big(H^{(l)} +\n",
    "\\mathrm{MHA}(H^{(l)}, H^{(l)}, H^{(l)})\\Big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "H^{(l+1)} = \\mathrm{LN}\\Big(H^{(l)} + \\mathrm{FFN}(H^{(l)})\\Big)\n",
    "$$\n",
    "\n",
    "The final hidden state \\(H_T\\) serves as a context summary for decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "### Policy & Value Outputs\n",
    "\n",
    "$$\n",
    "\\pi_\\theta(a_t|\\mathcal{E}_t) =\n",
    "\\mathrm{Softmax}(\\mathrm{MLP}_{\\text{policy}}(H_T))\n",
    "$$\n",
    "\n",
    "$$\n",
    "V_\\phi(\\mathcal{E}_t) =\n",
    "\\mathrm{MLP}_{\\text{value}}(H_T)\n",
    "$$\n",
    "\n",
    "This allows PPO to act based on *recent experience*, not just a single observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (needed for 3D)\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding_3d(pos, num_freqs=4, max_freq=10.0):\n",
    "    \"\"\"\n",
    "    pos: np.array shape (3,) with (x, y, z) in [-space_size, space_size].\n",
    "    Returns: encoding vector of shape (3 * 2 * num_freqs,)\n",
    "    \"\"\"\n",
    "    pos = np.asarray(pos, dtype=np.float32)\n",
    "    assert pos.shape == (3,)\n",
    "\n",
    "    freqs = np.linspace(1.0, max_freq, num_freqs)\n",
    "    enc = []\n",
    "    for coord in pos:            # x, y, z\n",
    "        for f in freqs:\n",
    "            enc.append(np.sin(f * coord))\n",
    "            enc.append(np.cos(f * coord))\n",
    "    return np.array(enc, dtype=np.float32)\n",
    "\n",
    "\n",
    "class FrogFly3DEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    3D continuous environment:\n",
    "    - Frog (agent) moves to catch a moving fly.\n",
    "    - Observations: positions + relative vector + positional encodings.\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if config is None:\n",
    "            config = {}\n",
    "\n",
    "        self.space_size = float(config.get(\"space_size\", 1.0))\n",
    "        self.step_size = float(config.get(\"step_size\", 0.1))\n",
    "        self.fly_speed = float(config.get(\"fly_speed\", 0.05))\n",
    "        self.catch_radius = float(config.get(\"catch_radius\", 0.15))\n",
    "        self.max_steps = int(config.get(\"max_steps\", 200))\n",
    "        self.num_freqs = int(config.get(\"num_freqs\", 4))\n",
    "        self.use_positional_encodings = bool(\n",
    "            config.get(\"use_positional_encodings\", True)\n",
    "        )\n",
    "\n",
    "        # Action = 3D movement in [-1, 1]^3\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0, high=1.0, shape=(3,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Observation components\n",
    "        # frog_pos (3) + fly_pos (3) + rel (3) = 9\n",
    "        base_dim = 9\n",
    "        if self.use_positional_encodings:\n",
    "            pe_dim = 3 * 2 * self.num_freqs  # per position\n",
    "            obs_dim = base_dim + 2 * pe_dim\n",
    "        else:\n",
    "            obs_dim = base_dim\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-5.0, high=5.0, shape=(obs_dim,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.frog_pos = None\n",
    "        self.fly_pos = None\n",
    "        self.steps = 0\n",
    "        self._value_out = None\n",
    "\n",
    "    # ---------- Helpers ----------\n",
    "\n",
    "    def _sample_position(self):\n",
    "        return np.random.uniform(\n",
    "            low=-self.space_size,\n",
    "            high=self.space_size,\n",
    "            size=(3,),\n",
    "        ).astype(np.float32)\n",
    "\n",
    "    def _clip_position(self, pos):\n",
    "        return np.clip(pos, -self.space_size, self.space_size).astype(np.float32)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        rel = self.fly_pos - self.frog_pos\n",
    "        parts = [self.frog_pos, self.fly_pos, rel]\n",
    "\n",
    "        if self.use_positional_encodings:\n",
    "            frog_pe = positional_encoding_3d(self.frog_pos, self.num_freqs)\n",
    "            fly_pe = positional_encoding_3d(self.fly_pos, self.num_freqs)\n",
    "            parts.extend([frog_pe, fly_pe])\n",
    "\n",
    "        return np.concatenate(parts, axis=0).astype(np.float32)\n",
    "\n",
    "    def _get_distance(self):\n",
    "        return float(np.linalg.norm(self.fly_pos - self.frog_pos))\n",
    "\n",
    "    # ---------- Gymnasium API ----------\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.steps = 0\n",
    "        self.frog_pos = self._sample_position()\n",
    "        self.fly_pos = self._sample_position()\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.steps += 1\n",
    "\n",
    "        action = np.asarray(action, dtype=np.float32)\n",
    "        action = np.clip(action, -1.0, 1.0)\n",
    "\n",
    "        # Frog moves\n",
    "        self.frog_pos = self.frog_pos + self.step_size * action\n",
    "        self.frog_pos = self._clip_position(self.frog_pos)\n",
    "\n",
    "        # Fly moves randomly\n",
    "        fly_dir = np.random.normal(size=(3,)).astype(np.float32)\n",
    "        fly_dir /= np.linalg.norm(fly_dir) + 1e-8\n",
    "        self.fly_pos = self.fly_pos + self.fly_speed * fly_dir\n",
    "        self.fly_pos = self._clip_position(self.fly_pos)\n",
    "\n",
    "        dist = self._get_distance()\n",
    "        caught = dist < self.catch_radius\n",
    "\n",
    "        # Reward shaping: closer is better + bonus for catch\n",
    "        reward = -dist\n",
    "        if caught:\n",
    "            reward += 10.0\n",
    "\n",
    "        terminated = caught\n",
    "        truncated = self.steps >= self.max_steps\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = {\"distance\": dist, \"caught\": caught}\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        print(\n",
    "            f\"Step {self.steps} | \"\n",
    "            f\"Frog: {self.frog_pos} | Fly: {self.fly_pos} | \"\n",
    "            f\"Dist: {self._get_distance():.3f}\"\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "\n",
    "# K-step observation history wrapper (if you don't already have this)\n",
    "class ObsHistoryWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, K=8):\n",
    "        super().__init__(env)\n",
    "        self.K = K\n",
    "        obs_shape = env.observation_space.shape  # (D,)\n",
    "        self.history = np.zeros((K,) + obs_shape, dtype=np.float32)\n",
    "\n",
    "        low  = np.repeat(env.observation_space.low[None, :],  K, axis=0)\n",
    "        high = np.repeat(env.observation_space.high[None, :], K, axis=0)\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs)\n",
    "        self.history[:] = obs\n",
    "        return self.history.copy(), info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.history = np.roll(self.history, shift=-1, axis=0)\n",
    "        self.history[-1] = obs\n",
    "        return self.history.copy(), reward, terminated, truncated, info\n",
    "\n",
    "# Factory for RLlib\n",
    "def make_frog_hist_env(env_config):\n",
    "    base_env = FrogFly3DEnv(env_config)\n",
    "    return ObsHistoryWrapper(base_env, K=8)\n",
    "\n",
    "# Register under a name RLlib understands\n",
    "register_env(\"frog_hist_env\", make_frog_hist_env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 20:41:22,631\tINFO worker.py:2023 -- Started a local Ray instance.\n",
      "/opt/anaconda3/envs/rl-project/lib/python3.10/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "class FrogTransformerModel(TorchModelV2, nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_space,\n",
    "        action_space,\n",
    "        num_outputs,\n",
    "        model_config,\n",
    "        name,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        # Expect obs shape = (K, obs_dim_single)\n",
    "        assert len(obs_space.shape) == 2, f\"Expected (K, D), got {obs_space.shape}\"\n",
    "        self.seq_len    = obs_space.shape[0]  # K (time)\n",
    "        self.feature_dim = obs_space.shape[1] # D (per-timestep features)\n",
    "\n",
    "        cmc = model_config.get(\"custom_model_config\", {}) or {}\n",
    "\n",
    "        def get_hp(key, default):\n",
    "            return kwargs.get(key, cmc.get(key, default))\n",
    "\n",
    "        d_model    = get_hp(\"d_model\", 64)\n",
    "        nhead      = get_hp(\"nhead\", 4)\n",
    "        num_layers = get_hp(\"num_layers\", 1)\n",
    "        dim_ff     = get_hp(\"dim_feedforward\", 128)\n",
    "        dropout    = get_hp(\"dropout\", 0.1)\n",
    "\n",
    "        # Embedding per timestep (map R^{D} -> R^{d_model})\n",
    "        self.embed = nn.Linear(self.feature_dim, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, num_outputs),\n",
    "        )\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        self._features = None\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Get obs as float tensor, whatever its shape is\n",
    "        x = input_dict[\"obs\"].float()       # shape: (B, ...) with possibly >2 dims\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # Flatten all non-batch dims into a single feature dimension\n",
    "        x = x.view(B, -1)                   # shape: (B, F_flat)\n",
    "        F = x.shape[1]\n",
    "\n",
    "        # --- Infer how to interpret the obs as (B, K, D) sequence ---\n",
    "        # Case 1: env gives a single feature vector of length feature_dim → treat as K=1\n",
    "        if F == self.feature_dim:\n",
    "            K = 1\n",
    "        # Case 2: env gives a flattened sequence of length seq_len * feature_dim\n",
    "        elif F == self.seq_len * self.feature_dim:\n",
    "            K = self.seq_len\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                f\"Cannot reshape obs of size {F} into \"\n",
    "                f\"(B, K, feature_dim={self.feature_dim}) with seq_len={self.seq_len}.\"\n",
    "            )\n",
    "\n",
    "        # Reshape to (B, K, D)\n",
    "        x = x.view(B, K, self.feature_dim)\n",
    "\n",
    "        # --- Standard Transformer forward ---\n",
    "        # (B, K, D) → (B, K, d_model)\n",
    "        x = self.embed(x)\n",
    "\n",
    "        # Optional: positional encodings, if you defined self.pos_embed\n",
    "        if hasattr(self, \"pos_embed\"):\n",
    "            # assume pos_embed has shape (1, max_K, d_model)\n",
    "            x = x + self.pos_embed[:, :K, :]\n",
    "\n",
    "        # TransformerEncoder expects (K, B, d_model)\n",
    "        x = x.transpose(0, 1)          # (K, B, d_model)\n",
    "        x = self.transformer(x)        # (K, B, d_model)\n",
    "        x = x.transpose(0, 1)          # (B, K, d_model)\n",
    "\n",
    "        # Pooling: take last token\n",
    "        token = x[:, -1, :]            # (B, d_model)\n",
    "\n",
    "        # Policy and value heads\n",
    "        logits = self.policy_head(token)     # (B, num_actions)\n",
    "        value  = self.value_head(token)      # (B, 1)\n",
    "\n",
    "        # RLlib expects value via this attribute\n",
    "        self._value_out = value.squeeze(-1)  # (B,)\n",
    "\n",
    "        # Return logits + empty RNN state list\n",
    "        return logits, []\n",
    "\n",
    "    def value_function(self):\n",
    "        # RLlib calls this after forward() to get V(s).\n",
    "        if self._value_out is None:\n",
    "            raise ValueError(\"value_function() called before forward().\")\n",
    "        return self._value_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ModelCatalog.register_custom_model(\"frog_transformer_policy\", FrogTransformerModel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frog_env(env_config):\n",
    "    base_env = FrogFly3DEnv(env_config)\n",
    "    return ObsHistoryWrapper(base_env, K=8)  # e.g., last 8 obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 20:41:23,336\tWARNING 295355125.py:61 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "/opt/anaconda3/envs/rl-project/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:525: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/opt/anaconda3/envs/rl-project/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/anaconda3/envs/rl-project/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/anaconda3/envs/rl-project/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "[2025-11-29 20:41:23,419 E 89214 63533471] core_worker.cc:2223: Actor with class name: 'RolloutWorker' and ID: '1c56ac4ae78a1aae9faf52d301000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "2025-11-29 20:41:26,175\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Algo built OK with grad clipping\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "env_config = {\n",
    "    \"space_size\": 1.0,\n",
    "    \"step_size\": 0.1,\n",
    "    \"fly_speed\": 0.05,\n",
    "    \"catch_radius\": 0.15,\n",
    "    \"max_steps\": 200,\n",
    "    \"num_freqs\": 4,\n",
    "    \"use_positional_encodings\": True,\n",
    "}\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(\n",
    "        env=\"frog_hist_env\",    # registered history-wrapped env\n",
    "        env_config=env_config,\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=False,\n",
    "        enable_env_runner_and_connector_v2=False,\n",
    "    )\n",
    "    .env_runners(\n",
    "        num_env_runners=1,\n",
    "        num_envs_per_env_runner=4,\n",
    "        create_env_on_local_worker=True,\n",
    "    )\n",
    "    .resources(num_gpus=0)\n",
    "    .training(\n",
    "        model={\n",
    "            \"custom_model\": \"frog_transformer_policy\",\n",
    "            \"custom_model_config\": {\n",
    "                \"d_model\": 64,\n",
    "                \"nhead\": 4,\n",
    "                \"num_layers\": 1,\n",
    "                \"dim_feedforward\": 128,\n",
    "                \"dropout\": 0.1,\n",
    "                \"entropy_coeff\": 0.01\n",
    "            },\n",
    "        },\n",
    "        gamma=0.99,\n",
    "        lr=1e-4,          # a bit conservative to help with stability\n",
    "        grad_clip=0.5,    # gradient clipping threshold\n",
    "        grad_clip_by=\"global_norm\",  # (this is the default but being explicit)\n",
    "        train_batch_size=2000,\n",
    "        num_epochs=10,\n",
    "        minibatch_size=256,\n",
    "        clip_param=0.2,\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_duration=20,              # 20 eval episodes instead of 10\n",
    "        evaluation_duration_unit=\"episodes\", # interpret that as episodes\n",
    "        # optional, but good practice:\n",
    "        evaluation_config={\n",
    "            \"explore\": False,               # greedy eval\n",
    "        },\n",
    "    ) \n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "print(\"Algo built OK with grad clipping\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 20:41:26,825\tWARNING train_ops.py:114 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['custom_metrics', 'episode_media', 'info', 'env_runners', 'num_healthy_workers', 'actor_manager_num_outstanding_async_reqs', 'num_remote_worker_restarts', 'num_agent_steps_sampled', 'num_agent_steps_trained', 'num_env_steps_sampled', 'num_env_steps_trained', 'num_env_steps_sampled_this_iter', 'num_env_steps_trained_this_iter', 'num_env_steps_sampled_throughput_per_sec', 'num_env_steps_trained_throughput_per_sec', 'timesteps_total', 'num_env_steps_sampled_lifetime', 'num_agent_steps_sampled_lifetime', 'num_steps_trained_this_iter', 'agent_timesteps_total', 'timers', 'counters', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float64(0.4998383487973894), 'cur_kl_coeff': np.float64(0.19999999999999993), 'cur_lr': np.float64(0.00010000000000000005), 'total_loss': np.float64(10.217063985552107), 'policy_loss': np.float64(0.22095139612044606), 'vf_loss': np.float64(9.945556572505406), 'vf_explained_var': np.float64(-3.517270088195801e-05), 'kl': np.float64(0.25277980310576303), 'entropy': np.float64(4.178156311171396), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(256.0), 'num_grad_updates_lifetime': np.float64(35.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(34.5)}}, 'num_env_steps_sampled': 2000, 'num_env_steps_trained': 2000, 'num_agent_steps_sampled': 2000, 'num_agent_steps_trained': 2000}, 'env_runners': {'episode_reward_max': -277.2626935839653, 'episode_reward_min': -438.59973216056824, 'episode_reward_mean': np.float64(-347.49355387687683), 'episode_len_mean': np.float64(200.0), 'episode_media': {}, 'episodes_timesteps_total': 1600, 'policy_reward_min': {'default_policy': np.float64(-438.59973216056824)}, 'policy_reward_max': {'default_policy': np.float64(-277.2626935839653)}, 'policy_reward_mean': {'default_policy': np.float64(-347.49355387687683)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-410.7973089814186, -285.1350716948509, -438.59973216056824, -335.22756910324097, -277.2626935839653, -299.0457527041435, -419.53709971904755, -314.34320306777954], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-410.7973089814186, -285.1350716948509, -438.59973216056824, -335.22756910324097, -277.2626935839653, -299.0457527041435, -419.53709971904755, -314.34320306777954]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.39262019707533174), 'mean_inference_ms': np.float64(0.44186672050795867), 'mean_action_processing_ms': np.float64(0.16941852912217556), 'mean_env_wait_ms': np.float64(0.24839884744670812), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.003293156623840332), 'StateBufferConnector_ms': np.float64(0.009670853614807129), 'ViewRequirementAgentConnector_ms': np.float64(0.036460161209106445)}, 'num_episodes': 8, 'episode_return_max': -277.2626935839653, 'episode_return_min': -438.59973216056824, 'episode_return_mean': np.float64(-347.49355387687683), 'episodes_this_iter': 8}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 2000, 'num_agent_steps_trained': 2000, 'num_env_steps_sampled': 2000, 'num_env_steps_trained': 2000, 'num_env_steps_sampled_this_iter': 2000, 'num_env_steps_trained_this_iter': 2000, 'num_env_steps_sampled_throughput_per_sec': 813.2579750801226, 'num_env_steps_trained_throughput_per_sec': 813.2579750801226, 'timesteps_total': 2000, 'num_env_steps_sampled_lifetime': 2000, 'num_agent_steps_sampled_lifetime': 2000, 'num_steps_trained_this_iter': 2000, 'agent_timesteps_total': 2000, 'timers': {'training_iteration_time_ms': 2459.252, 'restore_workers_time_ms': 0.011, 'training_step_time_ms': 2459.219, 'sample_time_ms': 643.686, 'load_time_ms': 0.179, 'load_throughput': 11184810.667, 'learn_time_ms': 1812.467, 'learn_throughput': 1103.468, 'synch_weights_time_ms': 2.308}, 'counters': {'num_env_steps_sampled': 2000, 'num_env_steps_trained': 2000, 'num_agent_steps_sampled': 2000, 'num_agent_steps_trained': 2000}, 'done': False, 'training_iteration': 1, 'trial_id': 'default', 'date': '2025-11-29_20-41-28', 'timestamp': 1764466888, 'time_this_iter_s': 2.463502883911133, 'time_total_s': 2.463502883911133, 'pid': 89214, 'hostname': 'mac.lan', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {'type': 'StochasticSampling'}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'frog_hist_env', 'env_config': {'space_size': 1.0, 'step_size': 0.1, 'fly_speed': 0.05, 'catch_radius': 0.15, 'max_steps': 200, 'num_freqs': 4, 'use_positional_encodings': True}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0001, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2000, 'num_epochs': 10, 'minibatch_size': 256, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'frog_transformer_policy', 'custom_model_config': {'d_model': 64, 'nhead': 4, 'num_layers': 1, 'dim_feedforward': 128, 'dropout': 0.1, 'entropy_coeff': 0.01}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, '_prior_exploration_config': None, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x163ad9750>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 20, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 2.463502883911133, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': np.float64(23.8), 'ram_util_percent': np.float64(74.7)}}\n"
     ]
    }
   ],
   "source": [
    "res = algo.train()\n",
    "print(res.keys())\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: reward_mean=-302.10, len_mean=196.1\n",
      "Iter 2: reward_mean=-280.08, len_mean=190.6\n",
      "Iter 3: reward_mean=-279.93, len_mean=193.2\n",
      "Iter 4: reward_mean=-275.34, len_mean=192.1\n",
      "Iter 5: reward_mean=-270.60, len_mean=185.5\n",
      "Iter 6: reward_mean=-271.49, len_mean=186.0\n",
      "Iter 7: reward_mean=-271.92, len_mean=186.3\n",
      "Iter 8: reward_mean=-268.35, len_mean=187.5\n",
      "Iter 9: reward_mean=-264.21, len_mean=186.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2025-11-29 20:41:51,968 E 89265 63533779] (gcs_server) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[33m(raylet)\u001b[0m [2025-11-29 20:41:52,578 E 89269 63533883] (raylet) main.cc:979: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10: reward_mean=-262.99, len_mean=187.6\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    result = algo.train()\n",
    "\n",
    "    er = result[\"env_runners\"]  # shorthand\n",
    "\n",
    "    reward_mean = er[\"episode_return_mean\"]\n",
    "    len_mean    = er[\"episode_len_mean\"]\n",
    "\n",
    "    print(\n",
    "        f\"Iter {i+1}: \"\n",
    "        f\"reward_mean={float(reward_mean):.2f}, \"\n",
    "        f\"len_mean={float(len_mean):.1f}\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_metrics(result):\n",
    "    \"\"\"Extract mean reward and len from an RLlib result dict (env_runners layout).\"\"\"\n",
    "    er = result.get(\"env_runners\", {})\n",
    "    reward_mean = float(er.get(\"episode_return_mean\", float(\"nan\")))\n",
    "    len_mean    = float(er.get(\"episode_len_mean\", float(\"nan\")))\n",
    "    return reward_mean, len_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "eval_env = FrogFly3DEnv(env_config)  # reuse your env_config\n",
    "\n",
    "\n",
    "def evaluate_policy(algo, env, num_episodes=5, render=False):\n",
    "    \"\"\"\n",
    "    Evaluate a single-agent policy using the legacy RLlib API.\n",
    "\n",
    "    Uses algo.compute_single_action(obs, ...) which is the right call\n",
    "    for this RLlib version (compute_actions is multi-agent only here).\n",
    "    \"\"\"\n",
    "    returns = []\n",
    "    lengths = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        ep_ret = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        while not done:\n",
    "            # Single-agent action: returns (action, state_out, info)\n",
    "            action, _, _ = algo.compute_single_action(obs, explore=False)\n",
    "\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            ep_ret += reward\n",
    "            steps += 1\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "        returns.append(ep_ret)\n",
    "        lengths.append(steps)\n",
    "\n",
    "    return {\n",
    "        \"mean_return\": float(np.mean(returns)),\n",
    "        \"std_return\": float(np.std(returns)),\n",
    "        \"mean_length\": float(np.mean(lengths)),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=89279)\u001b[0m [2025-11-29 20:41:53,165 E 89279 63534113] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2025-11-29 20:41:53,317 E 89214 63533936] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter    1] train_reward= -264.13, train_len= 189.4\n",
      "[Iter    2] train_reward= -265.20, train_len= 189.4\n",
      "[Iter    3] train_reward= -262.02, train_len= 186.2\n",
      "[Iter    4] train_reward= -261.55, train_len= 189.4\n",
      "[Iter    5] train_reward= -266.31, train_len= 190.7\n",
      "[Iter    6] train_reward= -267.29, train_len= 192.1\n",
      "[Iter    7] train_reward= -265.35, train_len= 191.8\n",
      "[Iter    8] train_reward= -268.60, train_len= 191.8\n",
      "[Iter    9] train_reward= -264.10, train_len= 190.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 20:42:17,748\tWARNING 1093147107.py:24 -- DeprecationWarning: `compute_single_action` has been deprecated. `Algorithm.compute_single_action` should no longer be used. Get the RLModule instance through `Algorithm.get_module([module ID])`, then compute actions through `RLModule.forward_inference({'obs': [obs batch]})`. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter   10] train_reward= -271.45, train_len= 190.8 | eval_return= -169.00, eval_len= 185.2\n",
      "  ✅ New best eval_return=-169.00, saved to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=frog_transformer_checkpoints), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float64(0.5), 'cur_kl_coeff': np.float64(0.3000000000000001), 'cur_lr': np.float64(0.00010000000000000005), 'total_loss': np.float64(9.742842088426862), 'policy_loss': np.float64(0.05313177511229047), 'vf_loss': np.float64(9.687046296255929), 'vf_explained_var': np.float64(-0.0035369251455579487), 'kl': np.float64(0.008880073969651545), 'entropy': np.float64(4.169789668491909), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(256.0), 'num_grad_updates_lifetime': np.float64(1435.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(34.5)}}, 'num_env_steps_sampled': 42000, 'num_env_steps_trained': 42000, 'num_agent_steps_sampled': 42000, 'num_agent_steps_trained': 42000}, 'env_runners': {'episode_reward_max': -8.111094072461128, 'episode_reward_min': -490.3988268375397, 'episode_reward_mean': np.float64(-271.45218309745195), 'episode_len_mean': np.float64(190.78), 'episode_media': {}, 'episodes_timesteps_total': 19078, 'policy_reward_min': {'default_policy': np.float64(-490.3988268375397)}, 'policy_reward_max': {'default_policy': np.float64(-8.111094072461128)}, 'policy_reward_mean': {'default_policy': np.float64(-271.45218309745195)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-287.35541635751724, -238.69839715957642, -280.2947333455086, -273.95660108327866, -326.5430052280426, -307.9995086193085, -483.5160745382309, -265.8499232530594, -236.29669526219368, -265.69337874650955, -343.05832695961, -232.16035425662994, -311.773646235466, -335.2947874069214, -270.6635283231735, -203.3584503531456, -296.6049482226372, -8.111094072461128, -402.94034242630005, -426.0365831851959, -33.50748500227928, -154.10435423254967, -278.9015004038811, -219.27790367603302, -245.50867652893066, -336.26154667139053, -276.90473783016205, -241.56059420108795, -317.46443116664886, -360.125363945961, -181.85492727160454, -79.04296796023846, -338.94457602500916, -371.04242062568665, -102.15202295780182, -187.99209359288216, -197.84481805562973, -245.1100235581398, -193.00713688135147, -404.4034082889557, -419.2550424337387, -399.1687111854553, -272.7177681326866, -276.4517582654953, -490.3988268375397, -433.27343797683716, -181.08675339818, -9.818155817687511, -128.44509029388428, -238.77568566799164, -233.86598920822144, -290.0647486448288, -349.7755148410797, -293.0064106583595, -249.8450572490692, -268.84912526607513, -345.090833902359, -348.4953135251999, -267.5443770289421, -212.43311822414398, -267.5004439651966, -325.6783311367035, -197.61381247639656, -235.0391212105751, -366.95269799232483, -159.27187455445528, -284.81581139564514, -209.22657649219036, -144.03816065192223, -301.2104862332344, -394.43384170532227, -286.14278441667557, -263.9274643063545, -374.30260157585144, -241.78539037704468, -313.41078102588654, -369.1190767288208, -271.3882201015949, -318.609978556633, -44.56655377149582, -336.67529875040054, -228.72286480665207, -232.91820067167282, -226.97548538446426, -43.481188744306564, -401.70618855953217, -278.43549954891205, -214.21083480119705, -302.4891027212143, -170.08681544661522, -378.09391844272614, -393.25382149219513, -318.59840059280396, -368.59065771102905, -225.61092799901962, -338.79059064388275, -221.07551008462906, -290.45739781856537, -265.7972859144211, -270.635808467865], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 38, 200, 200, 69, 164, 200, 200, 200, 200, 200, 200, 200, 200, 200, 81, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 41, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 142, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 79, 200, 200, 200, 200, 64, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-287.35541635751724, -238.69839715957642, -280.2947333455086, -273.95660108327866, -326.5430052280426, -307.9995086193085, -483.5160745382309, -265.8499232530594, -236.29669526219368, -265.69337874650955, -343.05832695961, -232.16035425662994, -311.773646235466, -335.2947874069214, -270.6635283231735, -203.3584503531456, -296.6049482226372, -8.111094072461128, -402.94034242630005, -426.0365831851959, -33.50748500227928, -154.10435423254967, -278.9015004038811, -219.27790367603302, -245.50867652893066, -336.26154667139053, -276.90473783016205, -241.56059420108795, -317.46443116664886, -360.125363945961, -181.85492727160454, -79.04296796023846, -338.94457602500916, -371.04242062568665, -102.15202295780182, -187.99209359288216, -197.84481805562973, -245.1100235581398, -193.00713688135147, -404.4034082889557, -419.2550424337387, -399.1687111854553, -272.7177681326866, -276.4517582654953, -490.3988268375397, -433.27343797683716, -181.08675339818, -9.818155817687511, -128.44509029388428, -238.77568566799164, -233.86598920822144, -290.0647486448288, -349.7755148410797, -293.0064106583595, -249.8450572490692, -268.84912526607513, -345.090833902359, -348.4953135251999, -267.5443770289421, -212.43311822414398, -267.5004439651966, -325.6783311367035, -197.61381247639656, -235.0391212105751, -366.95269799232483, -159.27187455445528, -284.81581139564514, -209.22657649219036, -144.03816065192223, -301.2104862332344, -394.43384170532227, -286.14278441667557, -263.9274643063545, -374.30260157585144, -241.78539037704468, -313.41078102588654, -369.1190767288208, -271.3882201015949, -318.609978556633, -44.56655377149582, -336.67529875040054, -228.72286480665207, -232.91820067167282, -226.97548538446426, -43.481188744306564, -401.70618855953217, -278.43549954891205, -214.21083480119705, -302.4891027212143, -170.08681544661522, -378.09391844272614, -393.25382149219513, -318.59840059280396, -368.59065771102905, -225.61092799901962, -338.79059064388275, -221.07551008462906, -290.45739781856537, -265.7972859144211, -270.635808467865]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.39575378550957785), 'mean_inference_ms': np.float64(0.4435536849678231), 'mean_action_processing_ms': np.float64(0.16213997844165262), 'mean_env_wait_ms': np.float64(0.24504755158601113), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0015668869018554688), 'StateBufferConnector_ms': np.float64(0.001291036605834961), 'ViewRequirementAgentConnector_ms': np.float64(0.03240156173706055)}, 'num_episodes': 10, 'episode_return_max': -8.111094072461128, 'episode_return_min': -490.3988268375397, 'episode_return_mean': np.float64(-271.45218309745195), 'episodes_this_iter': 10}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 42000, 'num_agent_steps_trained': 42000, 'num_env_steps_sampled': 42000, 'num_env_steps_trained': 42000, 'num_env_steps_sampled_this_iter': 2000, 'num_env_steps_trained_this_iter': 2000, 'num_env_steps_sampled_throughput_per_sec': 818.0959699015557, 'num_env_steps_trained_throughput_per_sec': 818.0959699015557, 'timesteps_total': 42000, 'num_env_steps_sampled_lifetime': 42000, 'num_agent_steps_sampled_lifetime': 42000, 'num_steps_trained_this_iter': 2000, 'agent_timesteps_total': 42000, 'timers': {'training_iteration_time_ms': 2463.058, 'restore_workers_time_ms': 0.009, 'training_step_time_ms': 2463.031, 'sample_time_ms': 648.357, 'load_time_ms': 0.346, 'load_throughput': 5783651.407, 'learn_time_ms': 1811.923, 'learn_throughput': 1103.8, 'synch_weights_time_ms': 2.266}, 'counters': {'num_env_steps_sampled': 42000, 'num_env_steps_trained': 42000, 'num_agent_steps_sampled': 42000, 'num_agent_steps_trained': 42000}, 'done': False, 'training_iteration': 21, 'trial_id': 'default', 'date': '2025-11-29_20-42-17', 'timestamp': 1764466937, 'time_this_iter_s': 2.4493370056152344, 'time_total_s': 51.320472717285156, 'pid': 89214, 'hostname': 'mac.lan', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {'type': 'StochasticSampling'}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'frog_hist_env', 'env_config': {'space_size': 1.0, 'step_size': 0.1, 'fly_speed': 0.05, 'catch_radius': 0.15, 'max_steps': 200, 'num_freqs': 4, 'use_positional_encodings': True}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0001, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2000, 'num_epochs': 10, 'minibatch_size': 256, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'frog_transformer_policy', 'custom_model_config': {'d_model': 64, 'nhead': 4, 'num_layers': 1, 'dim_feedforward': 128, 'dropout': 0.1, 'entropy_coeff': 0.01}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, '_prior_exploration_config': None, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x163ad9750>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 20, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 51.320472717285156, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': np.float64(31.875), 'ram_util_percent': np.float64(74.725)}})\n",
      "[Iter   11] train_reward= -266.19, train_len= 190.3\n",
      "[Iter   12] train_reward= -264.13, train_len= 192.2\n",
      "[Iter   13] train_reward= -264.07, train_len= 190.0\n",
      "[Iter   14] train_reward= -255.20, train_len= 187.9\n",
      "[Iter   15] train_reward= -254.12, train_len= 187.7\n",
      "[Iter   16] train_reward= -256.90, train_len= 187.7\n",
      "[Iter   17] train_reward= -248.06, train_len= 182.7\n",
      "[Iter   18] train_reward= -253.50, train_len= 185.2\n",
      "[Iter   19] train_reward= -251.28, train_len= 185.2\n",
      "[Iter   20] train_reward= -250.32, train_len= 181.7 | eval_return= -338.89, eval_len= 200.0\n",
      "[Iter   21] train_reward= -255.18, train_len= 181.7\n",
      "[Iter   22] train_reward= -267.87, train_len= 186.5\n",
      "[Iter   23] train_reward= -267.08, train_len= 186.1\n",
      "[Iter   24] train_reward= -263.02, train_len= 186.0\n",
      "[Iter   25] train_reward= -257.72, train_len= 186.0\n",
      "[Iter   26] train_reward= -262.93, train_len= 187.9\n",
      "[Iter   27] train_reward= -257.12, train_len= 186.7\n",
      "[Iter   28] train_reward= -252.07, train_len= 186.1\n",
      "[Iter   29] train_reward= -261.65, train_len= 190.1\n",
      "[Iter   30] train_reward= -260.55, train_len= 188.6 | eval_return= -312.14, eval_len= 200.0\n",
      "[Iter   31] train_reward= -261.27, train_len= 188.6\n",
      "[Iter   32] train_reward= -260.99, train_len= 189.9\n",
      "[Iter   33] train_reward= -264.63, train_len= 192.7\n",
      "[Iter   34] train_reward= -269.56, train_len= 191.5\n",
      "[Iter   35] train_reward= -274.99, train_len= 190.1\n",
      "[Iter   36] train_reward= -280.10, train_len= 193.3\n",
      "[Iter   37] train_reward= -284.03, train_len= 193.1\n",
      "[Iter   38] train_reward= -285.11, train_len= 193.7\n",
      "[Iter   39] train_reward= -279.95, train_len= 191.6\n",
      "[Iter   40] train_reward= -278.19, train_len= 191.1 | eval_return= -207.88, eval_len= 200.0\n",
      "[Iter   41] train_reward= -278.88, train_len= 191.1\n",
      "[Iter   42] train_reward= -283.93, train_len= 191.1\n",
      "[Iter   43] train_reward= -277.73, train_len= 191.1\n",
      "[Iter   44] train_reward= -275.30, train_len= 191.7\n",
      "[Iter   45] train_reward= -271.58, train_len= 191.0\n",
      "[Iter   46] train_reward= -269.81, train_len= 191.0\n",
      "[Iter   47] train_reward= -264.13, train_len= 191.4\n",
      "[Iter   48] train_reward= -264.39, train_len= 189.2\n",
      "[Iter   49] train_reward= -266.06, train_len= 189.8\n",
      "[Iter   50] train_reward= -263.45, train_len= 191.6 | eval_return= -333.63, eval_len= 200.0\n",
      "[Iter   51] train_reward= -251.47, train_len= 188.7\n",
      "[Iter   52] train_reward= -253.90, train_len= 188.7\n",
      "[Iter   53] train_reward= -252.93, train_len= 189.1\n",
      "[Iter   54] train_reward= -256.12, train_len= 190.5\n",
      "[Iter   55] train_reward= -257.96, train_len= 190.5\n",
      "[Iter   56] train_reward= -259.89, train_len= 189.7\n",
      "[Iter   57] train_reward= -263.52, train_len= 191.2\n",
      "[Iter   58] train_reward= -264.78, train_len= 190.5\n",
      "[Iter   59] train_reward= -268.15, train_len= 192.1\n",
      "[Iter   60] train_reward= -274.66, train_len= 192.1 | eval_return= -232.34, eval_len= 167.4\n",
      "[Iter   61] train_reward= -278.03, train_len= 192.5\n",
      "[Iter   62] train_reward= -274.19, train_len= 192.5\n",
      "[Iter   63] train_reward= -276.77, train_len= 193.2\n",
      "[Iter   64] train_reward= -277.67, train_len= 192.8\n",
      "[Iter   65] train_reward= -266.51, train_len= 192.8\n",
      "[Iter   66] train_reward= -269.18, train_len= 193.4\n",
      "[Iter   67] train_reward= -263.13, train_len= 193.4\n",
      "[Iter   68] train_reward= -265.01, train_len= 193.5\n",
      "[Iter   69] train_reward= -256.63, train_len= 191.7\n",
      "[Iter   70] train_reward= -252.49, train_len= 191.5 | eval_return= -299.92, eval_len= 200.0\n",
      "[Iter   71] train_reward= -246.64, train_len= 190.2\n",
      "[Iter   72] train_reward= -247.04, train_len= 190.2\n",
      "[Iter   73] train_reward= -250.71, train_len= 189.9\n",
      "[Iter   74] train_reward= -253.78, train_len= 189.9\n",
      "[Iter   75] train_reward= -253.35, train_len= 187.6\n",
      "[Iter   76] train_reward= -258.69, train_len= 188.0\n",
      "[Iter   77] train_reward= -259.91, train_len= 189.1\n",
      "[Iter   78] train_reward= -260.33, train_len= 190.1\n",
      "[Iter   79] train_reward= -263.25, train_len= 190.6\n",
      "[Iter   80] train_reward= -255.92, train_len= 188.4 | eval_return= -263.07, eval_len= 200.0\n",
      "[Iter   81] train_reward= -258.34, train_len= 190.5\n",
      "[Iter   82] train_reward= -254.03, train_len= 191.2\n",
      "[Iter   83] train_reward= -251.34, train_len= 191.2\n",
      "[Iter   84] train_reward= -240.53, train_len= 189.9\n",
      "[Iter   85] train_reward= -242.12, train_len= 192.0\n",
      "[Iter   86] train_reward= -237.98, train_len= 192.0\n",
      "[Iter   87] train_reward= -236.61, train_len= 193.4\n",
      "[Iter   88] train_reward= -237.75, train_len= 193.4\n",
      "[Iter   89] train_reward= -230.69, train_len= 190.9\n",
      "[Iter   90] train_reward= -235.81, train_len= 192.7 | eval_return= -257.40, eval_len= 200.0\n",
      "[Iter   91] train_reward= -232.32, train_len= 189.7\n",
      "[Iter   92] train_reward= -227.08, train_len= 188.6\n",
      "[Iter   93] train_reward= -230.38, train_len= 189.9\n",
      "[Iter   94] train_reward= -227.11, train_len= 189.3\n",
      "[Iter   95] train_reward= -225.74, train_len= 185.9\n",
      "[Iter   96] train_reward= -227.09, train_len= 185.3\n",
      "[Iter   97] train_reward= -223.68, train_len= 184.5\n",
      "[Iter   98] train_reward= -226.80, train_len= 187.0\n",
      "[Iter   99] train_reward= -229.11, train_len= 187.0\n",
      "[Iter  100] train_reward= -227.21, train_len= 188.0 | eval_return= -231.37, eval_len= 200.0\n",
      "[Iter  101] train_reward= -227.06, train_len= 190.7\n",
      "[Iter  102] train_reward= -219.55, train_len= 186.1\n",
      "[Iter  103] train_reward= -216.62, train_len= 187.0\n",
      "[Iter  104] train_reward= -210.46, train_len= 187.1\n",
      "[Iter  105] train_reward= -207.37, train_len= 186.8\n",
      "[Iter  106] train_reward= -206.10, train_len= 184.7\n",
      "[Iter  107] train_reward= -203.50, train_len= 181.7\n",
      "[Iter  108] train_reward= -200.35, train_len= 180.3\n",
      "[Iter  109] train_reward= -192.50, train_len= 177.6\n",
      "[Iter  110] train_reward= -191.00, train_len= 174.5 | eval_return= -363.71, eval_len= 200.0\n",
      "[Iter  111] train_reward= -196.73, train_len= 177.2\n",
      "[Iter  112] train_reward= -195.33, train_len= 174.7\n",
      "[Iter  113] train_reward= -201.24, train_len= 176.4\n",
      "[Iter  114] train_reward= -195.67, train_len= 177.3\n",
      "[Iter  115] train_reward= -198.43, train_len= 178.1\n",
      "[Iter  116] train_reward= -196.00, train_len= 181.8\n",
      "[Iter  117] train_reward= -192.39, train_len= 178.8\n",
      "[Iter  118] train_reward= -195.85, train_len= 181.8\n",
      "[Iter  119] train_reward= -197.58, train_len= 185.0\n",
      "[Iter  120] train_reward= -195.63, train_len= 187.4 | eval_return= -273.47, eval_len= 200.0\n",
      "[Iter  121] train_reward= -194.27, train_len= 187.5\n",
      "[Iter  122] train_reward= -188.91, train_len= 182.2\n",
      "[Iter  123] train_reward= -191.83, train_len= 183.1\n",
      "[Iter  124] train_reward= -187.72, train_len= 182.9\n",
      "[Iter  125] train_reward= -183.44, train_len= 182.0\n",
      "[Iter  126] train_reward= -183.04, train_len= 184.7\n",
      "[Iter  127] train_reward= -186.95, train_len= 185.1\n",
      "[Iter  128] train_reward= -182.94, train_len= 181.6\n",
      "[Iter  129] train_reward= -186.00, train_len= 181.7\n",
      "[Iter  130] train_reward= -186.47, train_len= 182.9 | eval_return= -338.34, eval_len= 200.0\n",
      "[Iter  131] train_reward= -190.11, train_len= 184.0\n",
      "[Iter  132] train_reward= -196.45, train_len= 186.6\n",
      "[Iter  133] train_reward= -199.23, train_len= 187.6\n",
      "[Iter  134] train_reward= -203.61, train_len= 186.7\n",
      "[Iter  135] train_reward= -207.12, train_len= 186.7\n",
      "[Iter  136] train_reward= -202.36, train_len= 184.1\n",
      "[Iter  137] train_reward= -204.97, train_len= 186.7\n",
      "[Iter  138] train_reward= -205.99, train_len= 186.6\n",
      "[Iter  139] train_reward= -204.44, train_len= 183.6\n",
      "[Iter  140] train_reward= -203.15, train_len= 185.2 | eval_return= -322.31, eval_len= 200.0\n",
      "[Iter  141] train_reward= -202.28, train_len= 185.2\n",
      "[Iter  142] train_reward= -199.58, train_len= 184.5\n",
      "[Iter  143] train_reward= -195.32, train_len= 183.1\n",
      "[Iter  144] train_reward= -186.83, train_len= 179.2\n",
      "[Iter  145] train_reward= -191.20, train_len= 183.1\n",
      "[Iter  146] train_reward= -192.51, train_len= 184.8\n",
      "[Iter  147] train_reward= -190.98, train_len= 184.1\n",
      "[Iter  148] train_reward= -191.88, train_len= 186.0\n",
      "[Iter  149] train_reward= -189.40, train_len= 187.8\n",
      "[Iter  150] train_reward= -184.02, train_len= 184.3 | eval_return= -231.84, eval_len= 200.0\n",
      "[Iter  151] train_reward= -181.66, train_len= 183.8\n",
      "[Iter  152] train_reward= -180.53, train_len= 184.2\n",
      "[Iter  153] train_reward= -183.25, train_len= 187.0\n",
      "[Iter  154] train_reward= -181.83, train_len= 185.5\n",
      "[Iter  155] train_reward= -181.67, train_len= 185.1\n",
      "[Iter  156] train_reward= -181.31, train_len= 186.5\n",
      "[Iter  157] train_reward= -181.21, train_len= 185.9\n",
      "[Iter  158] train_reward= -183.72, train_len= 186.6\n",
      "[Iter  159] train_reward= -183.49, train_len= 185.1\n",
      "[Iter  160] train_reward= -183.97, train_len= 186.4 | eval_return= -284.65, eval_len= 200.0\n",
      "[Iter  161] train_reward= -187.93, train_len= 186.4\n",
      "[Iter  162] train_reward= -190.71, train_len= 186.9\n",
      "[Iter  163] train_reward= -190.37, train_len= 188.3\n",
      "[Iter  164] train_reward= -194.02, train_len= 189.8\n",
      "[Iter  165] train_reward= -190.85, train_len= 187.8\n",
      "[Iter  166] train_reward= -193.80, train_len= 188.1\n",
      "[Iter  167] train_reward= -193.94, train_len= 186.2\n",
      "[Iter  168] train_reward= -194.73, train_len= 188.0\n",
      "[Iter  169] train_reward= -193.46, train_len= 189.5\n",
      "[Iter  170] train_reward= -192.62, train_len= 189.3 | eval_return= -264.19, eval_len= 200.0\n",
      "[Iter  171] train_reward= -191.27, train_len= 189.8\n",
      "[Iter  172] train_reward= -188.33, train_len= 187.5\n",
      "[Iter  173] train_reward= -187.05, train_len= 185.4\n",
      "[Iter  174] train_reward= -187.91, train_len= 184.8\n",
      "[Iter  175] train_reward= -187.37, train_len= 185.6\n",
      "[Iter  176] train_reward= -183.72, train_len= 185.3\n",
      "[Iter  177] train_reward= -186.35, train_len= 187.8\n",
      "[Iter  178] train_reward= -184.37, train_len= 184.5\n",
      "[Iter  179] train_reward= -177.15, train_len= 182.6\n",
      "[Iter  180] train_reward= -181.97, train_len= 184.9 | eval_return= -168.94, eval_len= 178.8\n",
      "  ✅ New best eval_return=-168.94, saved to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=frog_transformer_checkpoints), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float64(0.5), 'cur_kl_coeff': np.float64(1.1390624999999994), 'cur_lr': np.float64(0.00010000000000000005), 'total_loss': np.float64(8.473049654279436), 'policy_loss': np.float64(-0.11549746789304273), 'vf_loss': np.float64(8.573371280942645), 'vf_explained_var': np.float64(0.06261416247912815), 'kl': np.float64(0.013323193615568536), 'entropy': np.float64(0.35864664683384556), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(256.0), 'num_grad_updates_lifetime': np.float64(13335.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(34.5)}}, 'num_env_steps_sampled': 382000, 'num_env_steps_trained': 382000, 'num_agent_steps_sampled': 382000, 'num_agent_steps_trained': 382000}, 'env_runners': {'episode_reward_max': 7.828998386859894, 'episode_reward_min': -427.2205716371536, 'episode_reward_mean': np.float64(-181.96849190551788), 'episode_len_mean': np.float64(184.89), 'episode_media': {}, 'episodes_timesteps_total': 18489, 'policy_reward_min': {'default_policy': np.float64(-427.2205716371536)}, 'policy_reward_max': {'default_policy': np.float64(7.828998386859894)}, 'policy_reward_mean': {'default_policy': np.float64(-181.96849190551788)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-146.04035690426826, -112.44564817845821, -307.35286194086075, -264.3639243841171, -6.574904754757881, -16.110809423029423, -163.15049239993095, -178.23715245723724, -127.26250663399696, -277.8136710524559, -235.56069600582123, -196.25632685422897, -198.73388677835464, -132.06620410084724, -290.66741505265236, -170.44190767407417, -56.56760421395302, -70.37732760608196, -204.58479416370392, -224.05683773756027, -177.60185152292252, -225.01167261600494, -167.39036297798157, -204.29028850793839, -257.6628604531288, -199.37634724378586, 3.6567902714014053, -108.86215814948082, -267.012644469738, -272.1954430937767, -44.62820054590702, -215.34202271699905, -219.0137488245964, -131.28873220086098, -266.0915555357933, -140.87186107039452, -190.15029081702232, -244.01677632331848, -263.27864879369736, -164.7610821723938, -290.3024193048477, -249.93176299333572, -274.7512799501419, -207.23797100782394, -241.01467621326447, -157.85361742973328, -159.02414372563362, -236.90657073259354, -137.77017962932587, -185.1712240576744, -249.48284935951233, -130.8631030023098, -219.2928881943226, -128.6142699867487, -169.2392946779728, -71.81915079802275, -236.50587630271912, -140.15074291825294, -186.4769940674305, -239.9934547841549, -240.9072345495224, -212.6463869214058, -118.09003430604935, -273.8395114541054, -182.87641268968582, -178.40759181976318, -168.26313200592995, -175.16082307696342, -61.509938195347786, -71.68117925524712, -225.96357703208923, -165.24457830190659, -153.98167195916176, 7.828998386859894, -147.6514944434166, -175.3453074991703, -242.9272358417511, -278.7217307090759, -292.7627212405205, -46.68918390572071, -114.0383574962616, -191.56137651205063, -58.89247150346637, -143.77766489982605, -133.6251532882452, -69.73373395949602, -194.20228213071823, -203.1061351299286, -184.87699460983276, -120.8774388730526, -185.09782695770264, -236.73164051771164, -165.77110567688942, -190.39787271618843, -272.9672119617462, -427.2205716371536, -93.13060979545116, -273.51901188492775, -183.0141443014145, -303.2092846632004], 'episode_lengths': [200, 200, 200, 200, 35, 55, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 101, 65, 200, 200, 200, 200, 200, 200, 200, 200, 19, 200, 200, 200, 68, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 77, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 124, 132, 200, 200, 200, 10, 200, 200, 200, 200, 200, 106, 200, 200, 131, 200, 200, 166, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], 'policy_default_policy_reward': [-146.04035690426826, -112.44564817845821, -307.35286194086075, -264.3639243841171, -6.574904754757881, -16.110809423029423, -163.15049239993095, -178.23715245723724, -127.26250663399696, -277.8136710524559, -235.56069600582123, -196.25632685422897, -198.73388677835464, -132.06620410084724, -290.66741505265236, -170.44190767407417, -56.56760421395302, -70.37732760608196, -204.58479416370392, -224.05683773756027, -177.60185152292252, -225.01167261600494, -167.39036297798157, -204.29028850793839, -257.6628604531288, -199.37634724378586, 3.6567902714014053, -108.86215814948082, -267.012644469738, -272.1954430937767, -44.62820054590702, -215.34202271699905, -219.0137488245964, -131.28873220086098, -266.0915555357933, -140.87186107039452, -190.15029081702232, -244.01677632331848, -263.27864879369736, -164.7610821723938, -290.3024193048477, -249.93176299333572, -274.7512799501419, -207.23797100782394, -241.01467621326447, -157.85361742973328, -159.02414372563362, -236.90657073259354, -137.77017962932587, -185.1712240576744, -249.48284935951233, -130.8631030023098, -219.2928881943226, -128.6142699867487, -169.2392946779728, -71.81915079802275, -236.50587630271912, -140.15074291825294, -186.4769940674305, -239.9934547841549, -240.9072345495224, -212.6463869214058, -118.09003430604935, -273.8395114541054, -182.87641268968582, -178.40759181976318, -168.26313200592995, -175.16082307696342, -61.509938195347786, -71.68117925524712, -225.96357703208923, -165.24457830190659, -153.98167195916176, 7.828998386859894, -147.6514944434166, -175.3453074991703, -242.9272358417511, -278.7217307090759, -292.7627212405205, -46.68918390572071, -114.0383574962616, -191.56137651205063, -58.89247150346637, -143.77766489982605, -133.6251532882452, -69.73373395949602, -194.20228213071823, -203.1061351299286, -184.87699460983276, -120.8774388730526, -185.09782695770264, -236.73164051771164, -165.77110567688942, -190.39787271618843, -272.9672119617462, -427.2205716371536, -93.13060979545116, -273.51901188492775, -183.0141443014145, -303.2092846632004]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.4007374144492749), 'mean_inference_ms': np.float64(0.4450475104464461), 'mean_action_processing_ms': np.float64(0.16549506171264838), 'mean_env_wait_ms': np.float64(0.24810019508539935), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0016007423400878906), 'StateBufferConnector_ms': np.float64(0.0013191699981689453), 'ViewRequirementAgentConnector_ms': np.float64(0.032508134841918945)}, 'num_episodes': 12, 'episode_return_max': 7.828998386859894, 'episode_return_min': -427.2205716371536, 'episode_return_mean': np.float64(-181.96849190551788), 'episodes_this_iter': 12}, 'num_healthy_workers': 1, 'actor_manager_num_outstanding_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 382000, 'num_agent_steps_trained': 382000, 'num_env_steps_sampled': 382000, 'num_env_steps_trained': 382000, 'num_env_steps_sampled_this_iter': 2000, 'num_env_steps_trained_this_iter': 2000, 'num_env_steps_sampled_throughput_per_sec': 813.4240537309681, 'num_env_steps_trained_throughput_per_sec': 813.4240537309681, 'timesteps_total': 382000, 'num_env_steps_sampled_lifetime': 382000, 'num_agent_steps_sampled_lifetime': 382000, 'num_steps_trained_this_iter': 2000, 'agent_timesteps_total': 382000, 'timers': {'training_iteration_time_ms': 2477.308, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 2477.282, 'sample_time_ms': 636.662, 'load_time_ms': 0.558, 'load_throughput': 3586101.231, 'learn_time_ms': 1837.796, 'learn_throughput': 1088.26, 'synch_weights_time_ms': 2.125}, 'counters': {'num_env_steps_sampled': 382000, 'num_env_steps_trained': 382000, 'num_agent_steps_sampled': 382000, 'num_agent_steps_trained': 382000}, 'done': False, 'training_iteration': 191, 'trial_id': 'default', 'date': '2025-11-29_20-49-33', 'timestamp': 1764467373, 'time_this_iter_s': 2.4644460678100586, 'time_total_s': 476.1481063365936, 'pid': 89214, 'hostname': 'mac.lan', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {'type': 'StochasticSampling'}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'frog_hist_env', 'env_config': {'space_size': 1.0, 'step_size': 0.1, 'fly_speed': 0.05, 'catch_radius': 0.15, 'max_steps': 200, 'num_freqs': 4, 'use_positional_encodings': True}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0001, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2000, 'num_epochs': 10, 'minibatch_size': 256, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'frog_transformer_policy', 'custom_model_config': {'d_model': 64, 'nhead': 4, 'num_layers': 1, 'dim_feedforward': 128, 'dropout': 0.1, 'entropy_coeff': 0.01}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, '_prior_exploration_config': None, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x163ad9750>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 20, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': {'explore': False}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 476.1481063365936, 'iterations_since_restore': 191, 'perf': {'cpu_util_percent': np.float64(25.625), 'ram_util_percent': np.float64(76.025)}})\n",
      "[Iter  181] train_reward= -184.50, train_len= 185.4\n",
      "[Iter  182] train_reward= -188.60, train_len= 187.8\n",
      "[Iter  183] train_reward= -190.06, train_len= 189.2\n",
      "[Iter  184] train_reward= -182.58, train_len= 185.9\n",
      "[Iter  185] train_reward= -181.17, train_len= 185.0\n",
      "[Iter  186] train_reward= -178.42, train_len= 182.6\n",
      "[Iter  187] train_reward= -181.84, train_len= 185.9\n",
      "[Iter  188] train_reward= -183.11, train_len= 186.5\n",
      "[Iter  189] train_reward= -187.85, train_len= 185.8\n",
      "[Iter  190] train_reward= -181.92, train_len= 186.1 | eval_return= -249.03, eval_len= 200.0\n",
      "[Iter  191] train_reward= -181.93, train_len= 187.0\n",
      "[Iter  192] train_reward= -177.98, train_len= 186.3\n",
      "[Iter  193] train_reward= -184.66, train_len= 190.3\n",
      "[Iter  194] train_reward= -181.38, train_len= 190.6\n",
      "[Iter  195] train_reward= -185.05, train_len= 192.4\n",
      "[Iter  196] train_reward= -186.62, train_len= 191.1\n",
      "[Iter  197] train_reward= -186.34, train_len= 192.1\n",
      "[Iter  198] train_reward= -185.71, train_len= 190.9\n",
      "[Iter  199] train_reward= -182.86, train_len= 191.4\n",
      "[Iter  200] train_reward= -186.40, train_len= 192.5 | eval_return= -292.49, eval_len= 200.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_iterations = 200        # how long you want to train\n",
    "eval_interval  = 10         # how often to run eval\n",
    "eval_episodes  = 5\n",
    "\n",
    "train_history = []          # for plotting later\n",
    "best_eval_return = -float(\"inf\")\n",
    "checkpoint_dir = \"frog_transformer_checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # ---- 1. One PPO training iteration ----\n",
    "    result = algo.train()\n",
    "    train_reward, train_len = get_train_metrics(result)\n",
    "\n",
    "    # ---- 2. Periodic evaluation ----\n",
    "    if i % eval_interval == 0:\n",
    "        eval_stats = evaluate_policy(\n",
    "            algo,\n",
    "            eval_env,\n",
    "            num_episodes=eval_episodes,\n",
    "            render=False,\n",
    "        )\n",
    "        eval_return = eval_stats[\"mean_return\"]\n",
    "        eval_len    = eval_stats[\"mean_length\"]\n",
    "\n",
    "        print(\n",
    "            f\"[Iter {i:4d}] \"\n",
    "            f\"train_reward={train_reward:8.2f}, \"\n",
    "            f\"train_len={train_len:6.1f} | \"\n",
    "            f\"eval_return={eval_return:8.2f}, \"\n",
    "            f\"eval_len={eval_len:6.1f}\"\n",
    "        )\n",
    "\n",
    "        # Save history for plotting\n",
    "        train_history.append(\n",
    "            {\n",
    "                \"iter\": i,\n",
    "                \"train_reward\": train_reward,\n",
    "                \"train_len\": train_len,\n",
    "                \"eval_return\": eval_return,\n",
    "                \"eval_len\": eval_len,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # save best checkpoint\n",
    "        if eval_return > best_eval_return:\n",
    "            best_eval_return = eval_return\n",
    "            checkpoint_path = algo.save(checkpoint_dir)\n",
    "            print(f\"  New best eval_return={best_eval_return:.2f}, saved to {checkpoint_path}\")\n",
    "    else:\n",
    "        # Lighter log on non-eval iterations\n",
    "        print(\n",
    "            f\"[Iter {i:4d}] \"\n",
    "            f\"train_reward={train_reward:8.2f}, \"\n",
    "            f\"train_len={train_len:6.1f}\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_hist = pd.DataFrame(train_history)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df_hist[\"iter\"], df_hist[\"train_reward\"], label=\"train reward\")\n",
    "plt.plot(df_hist[\"iter\"], df_hist[\"eval_return\"], label=\"eval return\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Episode return\")\n",
    "plt.legend()\n",
    "plt.title(\"Frog Transformer PPO training\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
